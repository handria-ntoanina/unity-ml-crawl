{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to implement Prioritezed Experience according to explanation from Thomas Simonini from [here](https://medium.freecodecamp.org/improvements-in-deep-q-learning-dueling-double-dqn-prioritized-experience-replay-and-fixed-58b130cc5682)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from unityagents import UnityEnvironment\n",
    "from agents_maddpg.utils import OUNoise\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: CrawlerBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 129\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 20\n",
      "        Vector Action descriptions: , , , , , , , , , , , , , , , , , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"./Crawler_Windows_x86_64/Crawler.exe\")\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "num_agents = len(env_info.agents)\n",
    "states = env_info.vector_observations\n",
    "action_size = brain.vector_action_space_size\n",
    "state_size = states.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method to plot the progress of the agent's score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(scores):\n",
    "    # plot the scores\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.plot(np.arange(len(scores)), scores)\n",
    "    plt.ylabel('Score')\n",
    "    plt.xlabel('Episode #')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(agent, n_episodes=500, noise = 1, noise_reduction=0.9999, train_mode=True):\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=train_mode)[brain_name]\n",
    "        states = env_info.vector_observations\n",
    "        scores_one_episode = np.zeros(num_agents)\n",
    "        # reset the noise\n",
    "        agent.reset()\n",
    "        while True:\n",
    "            actions = agent.act(states, noise=noise)              # select an action (for each agent)\n",
    "                \n",
    "            env_info = env.step(np.clip(actions, -1, 1))[brain_name]              # send all actions to the environment\n",
    "            next_states = env_info.vector_observations                            # get next state (for each agent)\n",
    "            rewards = env_info.rewards                                            # get reward (for each agent)\n",
    "            # lets try to promote cooperation\n",
    "            dones = env_info.local_done                                           # see if episode finished\n",
    "            agent.step(states, actions, rewards, next_states, dones)       # learn\n",
    "            states = next_states                                                  # roll over states to next time step\n",
    "            \n",
    "            scores_one_episode += rewards\n",
    "            if np.any(dones):                                                     # exit loop if episode finished\n",
    "                break\n",
    "                \n",
    "        noise = max(noise * noise_reduction, 0.01)        \n",
    "        score = np.average(scores_one_episode)\n",
    "        scores.append(score)\n",
    "        scores_window.append(score)\n",
    "        mean_100 = np.mean(scores_window)\n",
    "\n",
    "        if i_episode % 50 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.3f}\\tMax Score: {:.3f}\\tNoise: {:.3f}'.\n",
    "                      format(i_episode, \n",
    "                         mean_100, \n",
    "                         np.max(scores_window),\n",
    "                        noise))\n",
    "            agent.save(\"eps_{}_avg_{}.pth\".format(i_episode, mean_100))\n",
    "            \n",
    "        if len(scores_window) >= 100 and np.mean(scores_window)>=2000:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.3f}'.format(i_episode, mean_100))\n",
    "            agent.save(\"final.pth\")\n",
    "            break\n",
    "            \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the agent\n",
    "* One instance of the memory ReplayBuffer is built here\n",
    "* The MADDPG is one version of the DDPG that use one local actor/critic network and one target actor/critic network that are being used by all agents.\n",
    "* The hyperparameters are set and the agent is initialized\n",
    "* Several instances of the noise generator are created and attached to the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from agents_maddpg.utils import ReplayBuffer, SimpleNoise\n",
    "from agents_maddpg.maddpg import MADDPG\n",
    "from agents_maddpg.model import ActorCritic\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "seed = 257\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "memory = ReplayBuffer(action_size, device, int(1e5), 256, seed)\n",
    "agent = MADDPG(states.shape[1], action_size, states.shape[0], memory, ActorCritic, device,\n",
    "                    GRADIENT_CLIP = 5,\n",
    "                    ACTIVATION = F.relu,\n",
    "                    TAU=1e-3,\n",
    "                    UPDATE_EVERY=32,\n",
    "                    TRANSFER_EVERY=1,\n",
    "                    UPDATE_LOOP=16,\n",
    "                    ADD_NOISE_EVERY=1,\n",
    "                    BOOTSTRAP_SIZE=4,\n",
    "                    LR_CRITIC = 3e-4,\n",
    "                    LR_ACTOR = 3e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\\MyDev\\Anaconda3\\envs\\drlnd\\lib\\site-packages\\torch\\nn\\functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 50\tAverage Score: 293.574\tMax Score: 1177.837\tNoise: 0.010\n",
      "Episode 100\tAverage Score: 292.396\tMax Score: 1177.837\tNoise: 0.010\n",
      "Episode 150\tAverage Score: 293.213\tMax Score: 627.467\tNoise: 0.010\n",
      "Episode 200\tAverage Score: 299.065\tMax Score: 650.084\tNoise: 0.010\n",
      "Episode 250\tAverage Score: 322.051\tMax Score: 1202.594\tNoise: 0.010\n",
      "Episode 300\tAverage Score: 347.288\tMax Score: 1202.594\tNoise: 0.010\n",
      "Episode 350\tAverage Score: 342.495\tMax Score: 1019.814\tNoise: 0.010\n",
      "Episode 400\tAverage Score: 341.326\tMax Score: 923.969\tNoise: 0.010\n",
      "Episode 450\tAverage Score: 358.104\tMax Score: 963.005\tNoise: 0.010\n",
      "Episode 500\tAverage Score: 364.428\tMax Score: 1124.668\tNoise: 0.010\n",
      "Episode 550\tAverage Score: 349.296\tMax Score: 1225.531\tNoise: 0.010\n",
      "Episode 600\tAverage Score: 375.422\tMax Score: 1225.531\tNoise: 0.010\n",
      "Episode 650\tAverage Score: 423.101\tMax Score: 1148.760\tNoise: 0.010\n",
      "Episode 700\tAverage Score: 432.078\tMax Score: 1221.634\tNoise: 0.010\n",
      "Episode 750\tAverage Score: 439.894\tMax Score: 1221.634\tNoise: 0.010\n",
      "Episode 800\tAverage Score: 441.429\tMax Score: 1159.793\tNoise: 0.010\n",
      "Episode 850\tAverage Score: 440.632\tMax Score: 1443.477\tNoise: 0.010\n",
      "Episode 900\tAverage Score: 446.005\tMax Score: 1443.477\tNoise: 0.010\n",
      "Episode 950\tAverage Score: 442.779\tMax Score: 1973.262\tNoise: 0.010\n",
      "Episode 1000\tAverage Score: 438.942\tMax Score: 1973.262\tNoise: 0.010\n",
      "Episode 1050\tAverage Score: 406.761\tMax Score: 1032.656\tNoise: 0.010\n",
      "Episode 1100\tAverage Score: 403.912\tMax Score: 993.761\tNoise: 0.010\n",
      "Episode 1150\tAverage Score: 414.339\tMax Score: 957.346\tNoise: 0.010\n",
      "Episode 1200\tAverage Score: 423.647\tMax Score: 1288.610\tNoise: 0.010\n",
      "Episode 1250\tAverage Score: 451.959\tMax Score: 1288.610\tNoise: 0.010\n",
      "Episode 1300\tAverage Score: 463.152\tMax Score: 1331.833\tNoise: 0.010\n",
      "Episode 1350\tAverage Score: 479.374\tMax Score: 1331.833\tNoise: 0.010\n",
      "Episode 1400\tAverage Score: 441.689\tMax Score: 1370.771\tNoise: 0.010\n",
      "Episode 1450\tAverage Score: 422.149\tMax Score: 1370.771\tNoise: 0.010\n",
      "Episode 1500\tAverage Score: 470.473\tMax Score: 1342.928\tNoise: 0.010\n",
      "Episode 1550\tAverage Score: 463.278\tMax Score: 1194.891\tNoise: 0.010\n",
      "Episode 1600\tAverage Score: 474.137\tMax Score: 1233.320\tNoise: 0.010\n",
      "Episode 1650\tAverage Score: 425.204\tMax Score: 1624.032\tNoise: 0.010\n",
      "Episode 1700\tAverage Score: 345.541\tMax Score: 1624.032\tNoise: 0.010\n",
      "Episode 1750\tAverage Score: 435.707\tMax Score: 1818.851\tNoise: 0.010\n",
      "Episode 1800\tAverage Score: 492.316\tMax Score: 1818.851\tNoise: 0.010\n",
      "Episode 1850\tAverage Score: 481.706\tMax Score: 1469.230\tNoise: 0.010\n",
      "Episode 1900\tAverage Score: 457.623\tMax Score: 1214.569\tNoise: 0.010\n",
      "Episode 1950\tAverage Score: 481.880\tMax Score: 1906.337\tNoise: 0.010\n",
      "Episode 2000\tAverage Score: 503.672\tMax Score: 1906.337\tNoise: 0.010\n",
      "Episode 2050\tAverage Score: 398.138\tMax Score: 1119.918\tNoise: 0.010\n",
      "Episode 2100\tAverage Score: 307.856\tMax Score: 1052.910\tNoise: 0.010\n",
      "Episode 2150\tAverage Score: 338.090\tMax Score: 1371.069\tNoise: 0.010\n",
      "Episode 2200\tAverage Score: 455.593\tMax Score: 1628.316\tNoise: 0.010\n",
      "Episode 2250\tAverage Score: 499.766\tMax Score: 1628.316\tNoise: 0.010\n",
      "Episode 2300\tAverage Score: 536.484\tMax Score: 2079.900\tNoise: 0.010\n",
      "Episode 2350\tAverage Score: 582.257\tMax Score: 2079.900\tNoise: 0.010\n",
      "Episode 2400\tAverage Score: 585.120\tMax Score: 1669.060\tNoise: 0.010\n",
      "Episode 2450\tAverage Score: 595.187\tMax Score: 1687.561\tNoise: 0.010\n",
      "Episode 2500\tAverage Score: 558.054\tMax Score: 1687.561\tNoise: 0.010\n",
      "Episode 2550\tAverage Score: 536.459\tMax Score: 2013.851\tNoise: 0.010\n",
      "Episode 2600\tAverage Score: 552.260\tMax Score: 2013.851\tNoise: 0.010\n",
      "Episode 2650\tAverage Score: 557.271\tMax Score: 1394.173\tNoise: 0.010\n",
      "Episode 2700\tAverage Score: 560.490\tMax Score: 2531.471\tNoise: 0.010\n",
      "Episode 2750\tAverage Score: 544.716\tMax Score: 2531.471\tNoise: 0.010\n",
      "Episode 2800\tAverage Score: 532.018\tMax Score: 1455.181\tNoise: 0.010\n",
      "Episode 2850\tAverage Score: 570.913\tMax Score: 1636.239\tNoise: 0.010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\\MyDev\\Anaconda3\\envs\\drlnd\\lib\\site-packages\\numpy\\core\\fromnumeric.py:83: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2900\tAverage Score: nan\tMax Score: nan\tNoise: 0.010\n",
      "Episode 2950\tAverage Score: nan\tMax Score: nan\tNoise: 0.010\n",
      "Episode 3000\tAverage Score: -0.575\tMax Score: -0.575\tNoise: 0.010\n",
      "Episode 3050\tAverage Score: -0.575\tMax Score: -0.575\tNoise: 0.010\n",
      "Episode 3100\tAverage Score: -0.575\tMax Score: -0.575\tNoise: 0.010\n",
      "Episode 3150\tAverage Score: -0.575\tMax Score: -0.575\tNoise: 0.010\n",
      "Episode 3200\tAverage Score: -0.575\tMax Score: -0.575\tNoise: 0.010\n",
      "Episode 3250\tAverage Score: -0.575\tMax Score: -0.575\tNoise: 0.010\n",
      "Episode 3300\tAverage Score: -0.575\tMax Score: -0.575\tNoise: 0.010\n",
      "Episode 3350\tAverage Score: -0.575\tMax Score: -0.575\tNoise: 0.010\n",
      "Episode 3400\tAverage Score: -0.575\tMax Score: -0.575\tNoise: 0.010\n",
      "Episode 3450\tAverage Score: -0.575\tMax Score: -0.575\tNoise: 0.010\n",
      "Episode 3500\tAverage Score: -0.575\tMax Score: -0.575\tNoise: 0.010\n",
      "Episode 3550\tAverage Score: -0.575\tMax Score: -0.575\tNoise: 0.010\n",
      "Episode 3600\tAverage Score: -0.575\tMax Score: -0.575\tNoise: 0.010\n",
      "Episode 3650\tAverage Score: -0.575\tMax Score: -0.575\tNoise: 0.010\n",
      "Episode 3700\tAverage Score: -0.575\tMax Score: -0.575\tNoise: 0.010\n",
      "Episode 3750\tAverage Score: -0.575\tMax Score: -0.575\tNoise: 0.010\n",
      "Episode 3800\tAverage Score: -0.575\tMax Score: -0.575\tNoise: 0.010\n",
      "Episode 3850\tAverage Score: -0.575\tMax Score: -0.575\tNoise: 0.010\n",
      "Episode 3900\tAverage Score: -0.575\tMax Score: -0.575\tNoise: 0.010\n",
      "Episode 3950\tAverage Score: -0.575\tMax Score: -0.575\tNoise: 0.010\n",
      "Episode 4000\tAverage Score: -0.575\tMax Score: -0.575\tNoise: 0.010\n",
      "Episode 4050\tAverage Score: -0.575\tMax Score: -0.575\tNoise: 0.010\n",
      "Episode 4100\tAverage Score: -0.575\tMax Score: -0.575\tNoise: 0.010\n",
      "Episode 4150\tAverage Score: -0.575\tMax Score: -0.575\tNoise: 0.010\n",
      "Episode 4200\tAverage Score: -0.575\tMax Score: -0.575\tNoise: 0.010\n",
      "Episode 4250\tAverage Score: -0.575\tMax Score: -0.575\tNoise: 0.010\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-50a717d9431a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mnoises\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mSimpleNoise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_noise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoises\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_episodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m60000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise_reduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.9996\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[0mplot_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-f63e328c1719>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(agent, n_episodes, noise, noise_reduction, train_mode)\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[1;31m# lets try to promote cooperation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mdones\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_done\u001b[0m                                           \u001b[1;31m# see if episode finished\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[1;33m)\u001b[0m       \u001b[1;31m# learn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_states\u001b[0m                                                  \u001b[1;31m# roll over states to next time step\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\MyDev\\deep learning\\unity-ml-crawl\\agents_maddpg\\maddpg.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, states, actions, rewards, next_states, dones)\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mu_step\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUPDATE_LOOP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m                 \u001b[0mt_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_step\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRANSFER_EVERY\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mt_step\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\MyDev\\deep learning\\unity-ml-crawl\\agents_maddpg\\maddpg.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[1;31m# optimize the actor by having the critic evaluating the value of the actor's decision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactor_optim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m         \u001b[0mactions_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork_local\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m         \u001b[0mmean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork_local\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;31m# during the back propagation, parameters of the actor that led to a bad note from the critic will be demoted, and good parameters that led to a good note will be promoted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mI:\\MyDev\\Anaconda3\\envs\\drlnd\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\MyDev\\deep learning\\unity-ml-crawl\\agents_maddpg\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mestimate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mI:\\MyDev\\Anaconda3\\envs\\drlnd\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\MyDev\\deep learning\\unity-ml-crawl\\agents_maddpg\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0mlinear\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mI:\\MyDev\\Anaconda3\\envs\\drlnd\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mI:\\MyDev\\Anaconda3\\envs\\drlnd\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mI:\\MyDev\\Anaconda3\\envs\\drlnd\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1026\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1028\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1029\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent.load(\"weights/eps_12250_avg_493.69921819451406.pth\")\n",
    "noises = [SimpleNoise(action_size, scale=1) for i in range(int(states.shape[1]))] \n",
    "agent.set_noise(noises)\n",
    "scores = train(agent, n_episodes=60000, noise = 0.01, noise_reduction = 0.9996, train_mode=True)\n",
    "plot_result(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\\MyDev\\Anaconda3\\envs\\drlnd\\lib\\site-packages\\torch\\nn\\functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 50\tAverage Score: 10.178\tMax Score: 20.448\tNoise: 0.998\n",
      "Episode 100\tAverage Score: 9.448\tMax Score: 25.383\tNoise: 0.996\n",
      "Episode 150\tAverage Score: 8.394\tMax Score: 25.383\tNoise: 0.994\n",
      "Episode 200\tAverage Score: 10.049\tMax Score: 31.791\tNoise: 0.992\n",
      "Episode 250\tAverage Score: 11.954\tMax Score: 31.791\tNoise: 0.990\n",
      "Episode 300\tAverage Score: 12.257\tMax Score: 39.518\tNoise: 0.988\n",
      "Episode 350\tAverage Score: 12.863\tMax Score: 39.518\tNoise: 0.986\n",
      "Episode 400\tAverage Score: 13.739\tMax Score: 40.364\tNoise: 0.984\n",
      "Episode 450\tAverage Score: 12.692\tMax Score: 40.364\tNoise: 0.982\n",
      "Episode 500\tAverage Score: 11.308\tMax Score: 29.803\tNoise: 0.980\n",
      "Episode 550\tAverage Score: 11.709\tMax Score: 30.133\tNoise: 0.978\n",
      "Episode 600\tAverage Score: 11.788\tMax Score: 32.765\tNoise: 0.976\n",
      "Episode 650\tAverage Score: 12.685\tMax Score: 32.765\tNoise: 0.974\n",
      "Episode 700\tAverage Score: 14.128\tMax Score: 29.359\tNoise: 0.972\n",
      "Episode 750\tAverage Score: 14.583\tMax Score: 37.219\tNoise: 0.970\n",
      "Episode 800\tAverage Score: 15.883\tMax Score: 44.368\tNoise: 0.969\n",
      "Episode 850\tAverage Score: 16.710\tMax Score: 44.368\tNoise: 0.967\n",
      "Episode 900\tAverage Score: 16.106\tMax Score: 40.531\tNoise: 0.965\n",
      "Episode 950\tAverage Score: 16.512\tMax Score: 44.733\tNoise: 0.963\n",
      "Episode 1000\tAverage Score: 16.329\tMax Score: 44.733\tNoise: 0.961\n",
      "Episode 1050\tAverage Score: 16.079\tMax Score: 34.602\tNoise: 0.959\n",
      "Episode 1100\tAverage Score: 16.018\tMax Score: 35.108\tNoise: 0.957\n",
      "Episode 1150\tAverage Score: 16.040\tMax Score: 36.896\tNoise: 0.955\n",
      "Episode 1200\tAverage Score: 16.762\tMax Score: 45.962\tNoise: 0.953\n",
      "Episode 1250\tAverage Score: 16.623\tMax Score: 45.962\tNoise: 0.951\n",
      "Episode 1300\tAverage Score: 17.477\tMax Score: 42.271\tNoise: 0.949\n",
      "Episode 1350\tAverage Score: 17.721\tMax Score: 38.527\tNoise: 0.947\n",
      "Episode 1400\tAverage Score: 16.483\tMax Score: 38.720\tNoise: 0.946\n",
      "Episode 1450\tAverage Score: 16.211\tMax Score: 38.720\tNoise: 0.944\n",
      "Episode 1500\tAverage Score: 15.959\tMax Score: 38.058\tNoise: 0.942\n",
      "Episode 1550\tAverage Score: 16.439\tMax Score: 35.818\tNoise: 0.940\n",
      "Episode 1600\tAverage Score: 16.301\tMax Score: 36.149\tNoise: 0.938\n",
      "Episode 1650\tAverage Score: 15.935\tMax Score: 36.149\tNoise: 0.936\n",
      "Episode 1700\tAverage Score: 16.568\tMax Score: 39.794\tNoise: 0.934\n",
      "Episode 1750\tAverage Score: 16.776\tMax Score: 48.475\tNoise: 0.932\n",
      "Episode 1800\tAverage Score: 16.075\tMax Score: 48.475\tNoise: 0.931\n",
      "Episode 1850\tAverage Score: 15.937\tMax Score: 38.770\tNoise: 0.929\n",
      "Episode 1900\tAverage Score: 15.940\tMax Score: 37.473\tNoise: 0.927\n",
      "Episode 1950\tAverage Score: 15.503\tMax Score: 38.209\tNoise: 0.925\n",
      "Episode 2000\tAverage Score: 16.490\tMax Score: 38.209\tNoise: 0.923\n",
      "Episode 2050\tAverage Score: 17.213\tMax Score: 34.698\tNoise: 0.921\n",
      "Episode 2100\tAverage Score: 16.246\tMax Score: 43.773\tNoise: 0.919\n",
      "Episode 2150\tAverage Score: 16.015\tMax Score: 43.773\tNoise: 0.918\n",
      "Episode 2200\tAverage Score: 17.114\tMax Score: 43.613\tNoise: 0.916\n",
      "Episode 2250\tAverage Score: 17.250\tMax Score: 42.699\tNoise: 0.914\n",
      "Episode 2300\tAverage Score: 18.366\tMax Score: 41.288\tNoise: 0.912\n",
      "Episode 2350\tAverage Score: 18.613\tMax Score: 41.301\tNoise: 0.910\n",
      "Episode 2400\tAverage Score: 17.432\tMax Score: 41.557\tNoise: 0.908\n",
      "Episode 2450\tAverage Score: 17.699\tMax Score: 56.150\tNoise: 0.907\n",
      "Episode 2500\tAverage Score: 18.566\tMax Score: 58.302\tNoise: 0.905\n",
      "Episode 2550\tAverage Score: 19.030\tMax Score: 58.302\tNoise: 0.903\n",
      "Episode 2600\tAverage Score: 18.811\tMax Score: 50.268\tNoise: 0.901\n",
      "Episode 2650\tAverage Score: 19.199\tMax Score: 72.276\tNoise: 0.899\n",
      "Episode 2700\tAverage Score: 19.384\tMax Score: 72.276\tNoise: 0.898\n",
      "Episode 2750\tAverage Score: 20.378\tMax Score: 58.874\tNoise: 0.896\n",
      "Episode 2800\tAverage Score: 19.814\tMax Score: 51.608\tNoise: 0.894\n",
      "Episode 2850\tAverage Score: 21.126\tMax Score: 72.888\tNoise: 0.892\n",
      "Episode 2900\tAverage Score: 22.076\tMax Score: 72.888\tNoise: 0.890\n",
      "Episode 2950\tAverage Score: 21.496\tMax Score: 57.688\tNoise: 0.889\n",
      "Episode 3000\tAverage Score: 22.511\tMax Score: 57.688\tNoise: 0.887\n",
      "Episode 3050\tAverage Score: 21.145\tMax Score: 58.869\tNoise: 0.885\n",
      "Episode 3100\tAverage Score: 20.586\tMax Score: 58.869\tNoise: 0.883\n",
      "Episode 3150\tAverage Score: 21.116\tMax Score: 57.099\tNoise: 0.882\n",
      "Episode 3200\tAverage Score: 21.086\tMax Score: 90.233\tNoise: 0.880\n",
      "Episode 3250\tAverage Score: 21.680\tMax Score: 90.233\tNoise: 0.878\n",
      "Episode 3300\tAverage Score: 21.161\tMax Score: 85.747\tNoise: 0.876\n",
      "Episode 3350\tAverage Score: 20.811\tMax Score: 61.481\tNoise: 0.875\n",
      "Episode 3400\tAverage Score: 22.109\tMax Score: 61.481\tNoise: 0.873\n",
      "Episode 3450\tAverage Score: 20.916\tMax Score: 50.908\tNoise: 0.871\n",
      "Episode 3500\tAverage Score: 19.471\tMax Score: 43.558\tNoise: 0.869\n",
      "Episode 3550\tAverage Score: 19.340\tMax Score: 39.611\tNoise: 0.868\n",
      "Episode 3600\tAverage Score: 21.606\tMax Score: 81.557\tNoise: 0.866\n",
      "Episode 3650\tAverage Score: 21.975\tMax Score: 81.557\tNoise: 0.864\n",
      "Episode 3700\tAverage Score: 22.247\tMax Score: 66.541\tNoise: 0.862\n",
      "Episode 3750\tAverage Score: 23.370\tMax Score: 68.927\tNoise: 0.861\n",
      "Episode 3800\tAverage Score: 21.977\tMax Score: 68.927\tNoise: 0.859\n",
      "Episode 3850\tAverage Score: 21.839\tMax Score: 64.583\tNoise: 0.857\n",
      "Episode 3900\tAverage Score: 21.023\tMax Score: 64.583\tNoise: 0.856\n",
      "Episode 3950\tAverage Score: 19.111\tMax Score: 52.725\tNoise: 0.854\n",
      "Episode 4000\tAverage Score: 19.497\tMax Score: 68.306\tNoise: 0.852\n",
      "Episode 4050\tAverage Score: 21.508\tMax Score: 69.612\tNoise: 0.850\n",
      "Episode 4100\tAverage Score: 21.079\tMax Score: 69.612\tNoise: 0.849\n",
      "Episode 4150\tAverage Score: 20.232\tMax Score: 65.367\tNoise: 0.847\n",
      "Episode 4200\tAverage Score: 22.063\tMax Score: 58.343\tNoise: 0.845\n",
      "Episode 4250\tAverage Score: 21.653\tMax Score: 78.571\tNoise: 0.844\n",
      "Episode 4300\tAverage Score: 18.613\tMax Score: 78.571\tNoise: 0.842\n",
      "Episode 4350\tAverage Score: 20.167\tMax Score: 67.934\tNoise: 0.840\n",
      "Episode 4400\tAverage Score: 21.843\tMax Score: 80.219\tNoise: 0.839\n",
      "Episode 4450\tAverage Score: 19.593\tMax Score: 80.219\tNoise: 0.837\n",
      "Episode 4500\tAverage Score: 20.484\tMax Score: 62.699\tNoise: 0.835\n",
      "Episode 4550\tAverage Score: 21.930\tMax Score: 53.873\tNoise: 0.834\n",
      "Episode 4600\tAverage Score: 21.767\tMax Score: 62.172\tNoise: 0.832\n",
      "Episode 4650\tAverage Score: 24.381\tMax Score: 84.170\tNoise: 0.830\n",
      "Episode 4700\tAverage Score: 24.737\tMax Score: 84.170\tNoise: 0.829\n",
      "Episode 4750\tAverage Score: 23.348\tMax Score: 67.450\tNoise: 0.827\n",
      "Episode 4800\tAverage Score: 23.173\tMax Score: 72.793\tNoise: 0.825\n",
      "Episode 4850\tAverage Score: 22.955\tMax Score: 72.793\tNoise: 0.824\n",
      "Episode 4900\tAverage Score: 23.530\tMax Score: 63.722\tNoise: 0.822\n",
      "Episode 4950\tAverage Score: 25.016\tMax Score: 85.703\tNoise: 0.820\n",
      "Episode 5000\tAverage Score: 25.442\tMax Score: 85.703\tNoise: 0.819\n",
      "Episode 5050\tAverage Score: 24.300\tMax Score: 66.564\tNoise: 0.817\n",
      "Episode 5100\tAverage Score: 24.158\tMax Score: 82.482\tNoise: 0.815\n",
      "Episode 5150\tAverage Score: 24.183\tMax Score: 82.482\tNoise: 0.814\n",
      "Episode 5200\tAverage Score: 25.275\tMax Score: 84.627\tNoise: 0.812\n",
      "Episode 5250\tAverage Score: 26.293\tMax Score: 84.627\tNoise: 0.811\n",
      "Episode 5300\tAverage Score: 25.806\tMax Score: 75.442\tNoise: 0.809\n",
      "Episode 5350\tAverage Score: 25.387\tMax Score: 79.728\tNoise: 0.807\n",
      "Episode 5400\tAverage Score: 26.950\tMax Score: 79.728\tNoise: 0.806\n",
      "Episode 5450\tAverage Score: 29.013\tMax Score: 68.311\tNoise: 0.804\n",
      "Episode 5500\tAverage Score: 27.370\tMax Score: 78.956\tNoise: 0.803\n",
      "Episode 5550\tAverage Score: 25.619\tMax Score: 78.956\tNoise: 0.801\n",
      "Episode 5600\tAverage Score: 28.520\tMax Score: 78.244\tNoise: 0.799\n",
      "Episode 5650\tAverage Score: 29.954\tMax Score: 78.244\tNoise: 0.798\n",
      "Episode 5700\tAverage Score: 28.017\tMax Score: 68.626\tNoise: 0.796\n",
      "Episode 5750\tAverage Score: 28.611\tMax Score: 98.147\tNoise: 0.795\n",
      "Episode 5800\tAverage Score: 32.474\tMax Score: 125.871\tNoise: 0.793\n",
      "Episode 5850\tAverage Score: 33.149\tMax Score: 125.871\tNoise: 0.791\n",
      "Episode 5900\tAverage Score: 34.007\tMax Score: 94.111\tNoise: 0.790\n",
      "Episode 5950\tAverage Score: 35.359\tMax Score: 106.273\tNoise: 0.788\n",
      "Episode 6000\tAverage Score: 34.259\tMax Score: 106.273\tNoise: 0.787\n",
      "Episode 6050\tAverage Score: 34.193\tMax Score: 133.885\tNoise: 0.785\n",
      "Episode 6100\tAverage Score: 33.080\tMax Score: 133.885\tNoise: 0.783\n",
      "Episode 6150\tAverage Score: 32.336\tMax Score: 114.733\tNoise: 0.782\n",
      "Episode 6200\tAverage Score: 32.413\tMax Score: 84.004\tNoise: 0.780\n",
      "Episode 6250\tAverage Score: 29.109\tMax Score: 82.532\tNoise: 0.779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 6300\tAverage Score: 29.812\tMax Score: 93.044\tNoise: 0.777\n",
      "Episode 6350\tAverage Score: 31.909\tMax Score: 93.044\tNoise: 0.776\n",
      "Episode 6400\tAverage Score: 29.951\tMax Score: 82.130\tNoise: 0.774\n",
      "Episode 6450\tAverage Score: 31.074\tMax Score: 86.401\tNoise: 0.773\n",
      "Episode 6500\tAverage Score: 32.366\tMax Score: 135.530\tNoise: 0.771\n",
      "Episode 6550\tAverage Score: 35.743\tMax Score: 135.530\tNoise: 0.770\n",
      "Episode 6600\tAverage Score: 38.630\tMax Score: 106.934\tNoise: 0.768\n",
      "Episode 6650\tAverage Score: 35.609\tMax Score: 135.522\tNoise: 0.766\n",
      "Episode 6700\tAverage Score: 34.026\tMax Score: 135.522\tNoise: 0.765\n",
      "Episode 6750\tAverage Score: 35.063\tMax Score: 99.647\tNoise: 0.763\n",
      "Episode 6800\tAverage Score: 35.541\tMax Score: 165.014\tNoise: 0.762\n",
      "Episode 6850\tAverage Score: 35.682\tMax Score: 165.014\tNoise: 0.760\n",
      "Episode 6900\tAverage Score: 34.070\tMax Score: 77.065\tNoise: 0.759\n",
      "Episode 6950\tAverage Score: 35.514\tMax Score: 122.057\tNoise: 0.757\n",
      "Episode 7000\tAverage Score: 38.370\tMax Score: 174.920\tNoise: 0.756\n",
      "Episode 7050\tAverage Score: 40.601\tMax Score: 185.923\tNoise: 0.754\n",
      "Episode 7100\tAverage Score: 40.274\tMax Score: 185.923\tNoise: 0.753\n",
      "Episode 7150\tAverage Score: 42.390\tMax Score: 192.196\tNoise: 0.751\n",
      "Episode 7200\tAverage Score: 42.408\tMax Score: 192.196\tNoise: 0.750\n",
      "Episode 7250\tAverage Score: 35.118\tMax Score: 114.337\tNoise: 0.748\n",
      "Episode 7300\tAverage Score: 37.277\tMax Score: 175.461\tNoise: 0.747\n",
      "Episode 7350\tAverage Score: 38.237\tMax Score: 175.461\tNoise: 0.745\n",
      "Episode 7400\tAverage Score: 35.911\tMax Score: 96.662\tNoise: 0.744\n",
      "Episode 7450\tAverage Score: 38.438\tMax Score: 157.782\tNoise: 0.742\n",
      "Episode 7500\tAverage Score: 39.009\tMax Score: 157.782\tNoise: 0.741\n",
      "Episode 7550\tAverage Score: 40.201\tMax Score: 108.765\tNoise: 0.739\n",
      "Episode 7600\tAverage Score: 40.289\tMax Score: 130.556\tNoise: 0.738\n",
      "Episode 7650\tAverage Score: 43.536\tMax Score: 189.156\tNoise: 0.736\n",
      "Episode 7700\tAverage Score: 47.149\tMax Score: 189.156\tNoise: 0.735\n",
      "Episode 7750\tAverage Score: 45.191\tMax Score: 140.100\tNoise: 0.733\n",
      "Episode 7800\tAverage Score: 41.655\tMax Score: 140.100\tNoise: 0.732\n",
      "Episode 7850\tAverage Score: 40.823\tMax Score: 128.645\tNoise: 0.731\n",
      "Episode 7900\tAverage Score: 44.828\tMax Score: 102.609\tNoise: 0.729\n",
      "Episode 7950\tAverage Score: 46.778\tMax Score: 118.792\tNoise: 0.728\n",
      "Episode 8000\tAverage Score: 49.321\tMax Score: 139.815\tNoise: 0.726\n",
      "Episode 8050\tAverage Score: 49.602\tMax Score: 150.975\tNoise: 0.725\n",
      "Episode 8100\tAverage Score: 46.403\tMax Score: 150.975\tNoise: 0.723\n",
      "Episode 8150\tAverage Score: 46.373\tMax Score: 133.612\tNoise: 0.722\n",
      "Episode 8200\tAverage Score: 49.468\tMax Score: 206.343\tNoise: 0.720\n",
      "Episode 8250\tAverage Score: 46.525\tMax Score: 206.343\tNoise: 0.719\n",
      "Episode 8300\tAverage Score: 46.635\tMax Score: 246.136\tNoise: 0.717\n",
      "Episode 8350\tAverage Score: 49.232\tMax Score: 246.136\tNoise: 0.716\n",
      "Episode 8400\tAverage Score: 49.372\tMax Score: 155.939\tNoise: 0.715\n",
      "Episode 8450\tAverage Score: 53.284\tMax Score: 191.510\tNoise: 0.713\n",
      "Episode 8500\tAverage Score: 55.799\tMax Score: 191.510\tNoise: 0.712\n",
      "Episode 8550\tAverage Score: 58.792\tMax Score: 167.120\tNoise: 0.710\n",
      "Episode 8600\tAverage Score: 59.379\tMax Score: 160.189\tNoise: 0.709\n",
      "Episode 8650\tAverage Score: 61.396\tMax Score: 189.079\tNoise: 0.708\n",
      "Episode 8700\tAverage Score: 61.012\tMax Score: 189.079\tNoise: 0.706\n",
      "Episode 8750\tAverage Score: 62.019\tMax Score: 182.723\tNoise: 0.705\n",
      "Episode 8800\tAverage Score: 62.873\tMax Score: 172.341\tNoise: 0.703\n",
      "Episode 8850\tAverage Score: 61.483\tMax Score: 172.969\tNoise: 0.702\n",
      "Episode 8900\tAverage Score: 60.863\tMax Score: 172.969\tNoise: 0.700\n",
      "Episode 8950\tAverage Score: 58.570\tMax Score: 146.972\tNoise: 0.699\n",
      "Episode 9000\tAverage Score: 61.719\tMax Score: 152.619\tNoise: 0.698\n",
      "Episode 9050\tAverage Score: 63.085\tMax Score: 152.619\tNoise: 0.696\n",
      "Episode 9100\tAverage Score: 61.717\tMax Score: 151.252\tNoise: 0.695\n",
      "Episode 9150\tAverage Score: 68.458\tMax Score: 240.195\tNoise: 0.693\n",
      "Episode 9200\tAverage Score: 68.871\tMax Score: 240.195\tNoise: 0.692\n",
      "Episode 9250\tAverage Score: 60.098\tMax Score: 223.116\tNoise: 0.691\n",
      "Episode 9300\tAverage Score: 60.149\tMax Score: 153.840\tNoise: 0.689\n",
      "Episode 9350\tAverage Score: 60.184\tMax Score: 202.769\tNoise: 0.688\n",
      "Episode 9400\tAverage Score: 62.799\tMax Score: 206.057\tNoise: 0.687\n",
      "Episode 9450\tAverage Score: 59.921\tMax Score: 206.057\tNoise: 0.685\n",
      "Episode 9500\tAverage Score: 57.195\tMax Score: 211.707\tNoise: 0.684\n",
      "Episode 9550\tAverage Score: 59.543\tMax Score: 211.707\tNoise: 0.682\n",
      "Episode 9600\tAverage Score: 57.170\tMax Score: 240.466\tNoise: 0.681\n",
      "Episode 9650\tAverage Score: 62.902\tMax Score: 240.466\tNoise: 0.680\n",
      "Episode 9700\tAverage Score: 61.554\tMax Score: 198.031\tNoise: 0.678\n",
      "Episode 9750\tAverage Score: 65.730\tMax Score: 287.420\tNoise: 0.677\n",
      "Episode 9800\tAverage Score: 72.655\tMax Score: 287.420\tNoise: 0.676\n",
      "Episode 9850\tAverage Score: 65.675\tMax Score: 214.400\tNoise: 0.674\n",
      "Episode 9900\tAverage Score: 62.189\tMax Score: 190.671\tNoise: 0.673\n",
      "Episode 9950\tAverage Score: 64.835\tMax Score: 282.084\tNoise: 0.672\n",
      "Episode 10000\tAverage Score: 70.206\tMax Score: 282.084\tNoise: 0.670\n",
      "Episode 10050\tAverage Score: 69.309\tMax Score: 246.973\tNoise: 0.669\n",
      "Episode 10100\tAverage Score: 67.462\tMax Score: 190.666\tNoise: 0.668\n",
      "Episode 10150\tAverage Score: 67.296\tMax Score: 171.016\tNoise: 0.666\n",
      "Episode 10200\tAverage Score: 73.657\tMax Score: 241.013\tNoise: 0.665\n",
      "Episode 10250\tAverage Score: 77.508\tMax Score: 241.013\tNoise: 0.664\n",
      "Episode 10300\tAverage Score: 70.190\tMax Score: 271.919\tNoise: 0.662\n",
      "Episode 10350\tAverage Score: 73.134\tMax Score: 333.786\tNoise: 0.661\n",
      "Episode 10400\tAverage Score: 82.079\tMax Score: 333.786\tNoise: 0.660\n",
      "Episode 10450\tAverage Score: 85.562\tMax Score: 267.211\tNoise: 0.658\n",
      "Episode 10500\tAverage Score: 76.388\tMax Score: 206.368\tNoise: 0.657\n",
      "Episode 10550\tAverage Score: 70.469\tMax Score: 209.882\tNoise: 0.656\n",
      "Episode 10600\tAverage Score: 67.402\tMax Score: 209.882\tNoise: 0.654\n",
      "Episode 10650\tAverage Score: 63.946\tMax Score: 181.671\tNoise: 0.653\n",
      "Episode 10700\tAverage Score: 72.499\tMax Score: 268.240\tNoise: 0.652\n",
      "Episode 10750\tAverage Score: 78.499\tMax Score: 268.240\tNoise: 0.651\n",
      "Episode 10800\tAverage Score: 77.651\tMax Score: 237.046\tNoise: 0.649\n"
     ]
    }
   ],
   "source": [
    "agent.load(\"weights/MADDPG/eps_2850_avg_570.9131032581789.pth\")\n",
    "noises = [SimpleNoise(action_size, scale=1) for i in range(int(states.shape[1]))] \n",
    "agent.set_noise(noises)\n",
    "scores = train(agent, n_episodes=60000, noise = 1, noise_reduction = 0.99996, train_mode=True)\n",
    "plot_result(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue the training with small noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 50\tAverage Score: 0.127\tMax Score: 1.400\tNoise: 0.010\n",
      "Episode 100\tAverage Score: 0.113\tMax Score: 1.400\tNoise: 0.010\n",
      "Episode 150\tAverage Score: 0.099\tMax Score: 0.200\tNoise: 0.010\n",
      "Episode 200\tAverage Score: 0.114\tMax Score: 1.200\tNoise: 0.010\n",
      "Episode 250\tAverage Score: 0.120\tMax Score: 1.200\tNoise: 0.010\n",
      "Episode 300\tAverage Score: 0.103\tMax Score: 0.300\tNoise: 0.010\n",
      "Episode 350\tAverage Score: 0.093\tMax Score: 0.300\tNoise: 0.010\n",
      "Episode 400\tAverage Score: 0.095\tMax Score: 0.900\tNoise: 0.010\n",
      "Episode 450\tAverage Score: 0.088\tMax Score: 0.900\tNoise: 0.010\n",
      "Episode 500\tAverage Score: 0.087\tMax Score: 0.200\tNoise: 0.010\n",
      "Episode 550\tAverage Score: 0.095\tMax Score: 0.200\tNoise: 0.010\n",
      "Episode 600\tAverage Score: 0.096\tMax Score: 0.100\tNoise: 0.010\n",
      "Episode 650\tAverage Score: 0.100\tMax Score: 0.200\tNoise: 0.010\n",
      "Episode 700\tAverage Score: 0.151\tMax Score: 2.000\tNoise: 0.010\n",
      "Episode 750\tAverage Score: 0.156\tMax Score: 2.000\tNoise: 0.010\n",
      "Episode 800\tAverage Score: 0.151\tMax Score: 2.600\tNoise: 0.010\n",
      "Episode 850\tAverage Score: 0.202\tMax Score: 2.600\tNoise: 0.010\n",
      "Episode 900\tAverage Score: 0.158\tMax Score: 2.600\tNoise: 0.010\n",
      "Episode 950\tAverage Score: 0.099\tMax Score: 0.290\tNoise: 0.010\n",
      "Episode 1000\tAverage Score: 0.232\tMax Score: 2.700\tNoise: 0.010\n",
      "Episode 1050\tAverage Score: 0.244\tMax Score: 2.700\tNoise: 0.010\n",
      "Episode 1100\tAverage Score: 0.130\tMax Score: 0.600\tNoise: 0.010\n",
      "Episode 1150\tAverage Score: 0.176\tMax Score: 2.700\tNoise: 0.010\n",
      "Episode 1200\tAverage Score: 0.161\tMax Score: 2.700\tNoise: 0.010\n",
      "Episode 1250\tAverage Score: 0.103\tMax Score: 0.200\tNoise: 0.010\n",
      "Episode 1300\tAverage Score: 0.172\tMax Score: 2.600\tNoise: 0.010\n",
      "Episode 1350\tAverage Score: 0.171\tMax Score: 2.600\tNoise: 0.010\n",
      "Episode 1400\tAverage Score: 0.096\tMax Score: 0.190\tNoise: 0.010\n",
      "Episode 1450\tAverage Score: 0.121\tMax Score: 2.600\tNoise: 0.010\n",
      "Episode 1500\tAverage Score: 0.218\tMax Score: 2.700\tNoise: 0.010\n",
      "Episode 1550\tAverage Score: 0.208\tMax Score: 2.700\tNoise: 0.010\n",
      "Episode 1600\tAverage Score: 0.218\tMax Score: 2.700\tNoise: 0.010\n",
      "Episode 1650\tAverage Score: 0.253\tMax Score: 2.700\tNoise: 0.010\n",
      "Episode 1700\tAverage Score: 0.183\tMax Score: 2.600\tNoise: 0.010\n",
      "Episode 1750\tAverage Score: 0.133\tMax Score: 2.600\tNoise: 0.010\n",
      "Episode 1800\tAverage Score: 0.466\tMax Score: 2.700\tNoise: 0.010\n",
      "\n",
      "Environment solved in 1802 episodes!\tAverage Score: 0.509\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = train(agent, n_episodes=2000, noise = 0.01, noise_reduction = 0.9996, train_mode=True)\n",
    "plot_result(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the trained agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.model import ActorCritic\n",
    "import torch.nn.functional as F\n",
    "device = \"cpu\"\n",
    "network = ActorCritic(state_size, action_size, state_size * 2 , F.leaky_relu ).to(device)\n",
    "network.eval()\n",
    "network.load_state_dict(torch.load(\"./final_weights/final_maddpg_local.pth\"))\n",
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "\n",
    "def act(network, states, device):\n",
    "    states = torch.from_numpy(states).float().unsqueeze(0).to(device)\n",
    "    ret = network(states).squeeze().cpu().data.numpy()\n",
    "    return ret\n",
    "\n",
    "for i in range(5):\n",
    "    while True:\n",
    "        actions = act(network, states, device)\n",
    "        env_info = env.step(np.clip(actions, -1, 1))[brain_name]  # send all actions to the environment\n",
    "        states = env_info.vector_observations                     # get next state (for each agent)\n",
    "        dones = env_info.local_done                               # see if episode finished\n",
    "        if np.any(dones):                                         # exit loop if episode finished\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
